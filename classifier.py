# -*- coding: utf-8 -*-
"""classifier_hotspot.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XDfOlIdKFtF8JUx6ujDAsgHiD45AuvyZ
"""

import warnings
warnings.filterwarnings(action='ignore',)

# Core:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt


# Machine Learning Algorithms"

from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier


from sklearn.metrics import matthews_corrcoef
from sklearn.metrics import precision_score


# Dataset Handle
from sklearn.model_selection import (train_test_split, cross_val_score, GridSearchCV)
from sklearn.preprocessing import StandardScaler


# Performance:
from sklearn.metrics import (confusion_matrix, accuracy_score, classification_report)

from sklearn.metrics import accuracy_score, \
        confusion_matrix, \
        roc_auc_score,\
        average_precision_score,\
        roc_curve, f1_score, recall_score, matthews_corrcoef, auc

X_kmer = np.load('K-mer.npy')
X_revk = np.load('rev-k-mer.npy')
X_gapk = np.load('gapped_k_mer.npy')

Y  = [1 for i in range(490)]
Y += [0 for i in range(591)]
Y = np.array(Y)
print(Y.shape)

X = np.concatenate((X_kmer,X_revk, X_gapk),axis=1)

from sklearn.utils import shuffle
X, Y = shuffle(X, Y, random_state=0)

print(X.shape)
print(Y.shape)

X

from sklearn.model_selection import train_test_split
Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.30, random_state=101)

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()

Xtrain = scaler.fit_transform(Xtrain)
Xtest = scaler.transform(Xtest)

classifiers = [
    LogisticRegression(),
    KNeighborsClassifier(n_neighbors=5),
    DecisionTreeClassifier(),
    SVC(kernel='rbf', probability=True),
    GaussianNB(),
    RandomForestClassifier(),
    AdaBoostClassifier(),
]

def auROCplot():
    ### auROC ###
    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='k', label='Random')
    plt.xlim([0.0, 1.00])
    plt.ylim([0.0, 1.02])
    plt.xlabel('False Positive Rate (FPR)')
    plt.ylabel('True Positive Rate (TPR)')
    # plt.title('Receiver Operating Characteristic (ROC)')
    plt.legend(loc='lower right')

    plt.savefig('auROC_classifier.png', dpi=100)
    plt.show()

for classifier in classifiers:
    model = classifier
    model.fit(Xtrain, Ytrain)

    # Task-1: 70/30
    Yp = model.predict(Xtest)

    #
    auROC = []

    mean_TPR = 0.0
    mean_FPR = np.linspace(0, 1, 100)

    FPR, TPR, _ = roc_curve(Ytest, Yp)
    mean_TPR += np.interp(mean_FPR, FPR, TPR)
    mean_TPR[0] = 0.0
    roc_auc = auc(FPR, TPR)

    auROC.append(roc_auc_score(Ytest, Yp))
    mean_TPR[-1] = 1.0
    mean_auc = auc(mean_FPR, mean_TPR)
    plt.plot(
    mean_FPR,
    mean_TPR,
    linestyle='-',
    label='{} ({:0.3f})'.format(classifier.__class__.__name__, mean_auc), lw=2.0)
    
    #

    Accuracy = []
    Sensitivity = []
    Specificity = []
    Precision = []
    MCC = []

    CM = confusion_matrix(y_pred=Yp, y_true=Ytest)
    TN, FP, FN, TP = CM.ravel()

    MCC.append(matthews_corrcoef(y_true=Ytest, y_pred=Yp))
    Sensitivity.append( TP / (TP + FN) )
    Specificity.append( TN / (TN + FP) )
    Precision.append(precision_score(y_true=Ytest, y_pred=Yp))

    accuracy = accuracy_score(y_true=Ytest, y_pred=Yp)
    print('Classifier: {}, Accuracy: {:0.2f}'.format(classifier.__class__.__name__, accuracy))
    print('Sensitivity: {0:.2f}'.format(np.mean(Sensitivity)))
    print('Specificity: {0:.2f}'.format(np.mean(Specificity)))
    print('MCC: {0:.2f}'.format(np.mean(MCC)))
    print('Precision: {0:.2f}'.format(np.mean(Precision)))
    
    # from sklearn.metrics import confusion_matrix
    # print(confusion_matrix(Ytest, Yp))

    print('_____________________________________________________')
    print()
auROCplot()